# Query-Rewriting
Query rewriting is the process of modifying a user's original search query 


# Query-Rewriting

Query rewritingì€ ì‚¬ìš©ìì˜ ì›ë˜ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìˆ˜ì •í•˜ëŠ” ê³¼ì •ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

---

## ğŸ“Œ ê°œìš”
Query rewriting(ì¿¼ë¦¬ ì¬ì‘ì„±)ì€ ê²€ìƒ‰ ì‹œìŠ¤í…œì´ë‚˜ AI ê¸°ë°˜ ì‘ë‹µ ì‹œìŠ¤í…œì—ì„œ ë§¤ìš° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.  
ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë” ì •í™•í•˜ê²Œ íŒŒì•…í•˜ê³ , ì¿¼ë¦¬ë¥¼ ì ì ˆí•œ í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ì˜ ì •í™•ë„ì™€ ê´€ë ¨ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## âœ¨ ì£¼ìš” ê¸°ëŠ¥
- **ìì—°ì–´ ê¸°ë°˜ ì¿¼ë¦¬ ì •ê·œí™”**
- **ì˜ë„ íŒŒì•…ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¿¼ë¦¬ ë³€í™˜**
- **ë©€í‹°í„´ ëŒ€í™” ì§€ì›**
- **ëª¨ë“ˆí˜• êµ¬ì¡°ë¡œ ì†ì‰¬ìš´ ì‹œìŠ¤í…œ í†µí•©**

---

## ğŸš€ í™œìš© ì‚¬ë¡€
- ê²€ìƒ‰ì—”ì§„ ê³ ë„í™” ë° ìµœì í™”
- ì±—ë´‡ ë° ëŒ€í™”í˜• AI ì‹œìŠ¤í…œ
- ì „ììƒê±°ë˜ ìƒí’ˆ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ
- RAG(Retrieval-Augmented Generation) ê¸°ë°˜ ì‘ë‹µ ìƒì„±

---

## ğŸ› ï¸ ì‚¬ìš© ê¸°ìˆ 
- **ì–¸ì–´**: Python
- **NLP ë¼ì´ë¸ŒëŸ¬ë¦¬**: spaCy, NLTK, Hugging Face Transformers
- **API**: RESTful API ë˜ëŠ” ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸

---

## ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°

| ë””ë ‰í† ë¦¬/íŒŒì¼        | ì„¤ëª…                              |
|----------------------|-----------------------------------|
| `data/`              | í•™ìŠµ ë° í‰ê°€ìš© ë°ì´í„°ì…‹           |
| `models/`            | ì‚¬ì „í•™ìŠµ ë˜ëŠ” ì»¤ìŠ¤í…€ ëª¨ë¸         |
| `src/`               | í•µì‹¬ ì½”ë“œ (ì „ì²˜ë¦¬, ëª¨ë¸ í˜¸ì¶œ ë“±) |
| `README.md`          | í”„ë¡œì íŠ¸ ì„¤ëª… íŒŒì¼                |

---

## ğŸ“„ ë¬¸ì„œ ê¸°ì—¬
ì´ ë¦¬í¬ì§€í† ë¦¬ëŠ” ì§€ì†ì ìœ¼ë¡œ ë°œì „ ì¤‘ì´ë©°, í”¼ë“œë°± ë° ê¸°ì—¬ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤.

# T5 ê¸°ë°˜ ê²€ìƒ‰ ì¿¼ë¦¬ ì¬ì‘ì„± í”„ë¡œì íŠ¸ (Query Rewriting with T5)

[![Python](https://img.shields.io/badge/Python-3.9%2B-blue?logo=python)](https://www.python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.x-orange?logo=pytorch)](https://pytorch.org/)
[![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Models-yellow)](https://huggingface.co/prhegde/t5-query-reformulation-RL)

ì‚¬ìš©ìì˜ ì›ë³¸ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ê²€ìƒ‰ ì—”ì§„ì— ë” ì¹œí™”ì ì¸ í˜•íƒœë¡œ ìˆ˜ì •í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ì˜ ì •í™•ë„ì™€ ê´€ë ¨ì„±ì„ ë†’ì´ëŠ” ì¿¼ë¦¬ ì¬ì‘ì„±(Query Rewriting) í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

---

### ğŸ“Œ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” ì‚¬ìš©ìì˜ ìì—°ì–´ ì¿¼ë¦¬ ì˜ë„ë¥¼ ë” ì •í™•í•˜ê²Œ íŒŒì•…í•˜ê³ , ì´ë¥¼ ê²€ìƒ‰ì— ìµœì í™”ëœ í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. `Hugging Face Transformers` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ ê°•ë ¥í•œ ì‚¬ì „ í•™ìŠµ ì–¸ì–´ ëª¨ë¸(T5)ì„ í™œìš©í•©ë‹ˆë‹¤.

### âœ¨ ì£¼ìš” ê¸°ëŠ¥

-   **ìì—°ì–´ ì¿¼ë¦¬ ì •ê·œí™”**: êµ¬ì–´ì²´, ì˜¤íƒˆì, ë¶ˆì™„ì „í•œ ë¬¸ì¥ ë“±ì„ ëª…í™•í•œ ì¿¼ë¦¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
-   **ì˜ë„ íŒŒì•… ê¸°ë°˜ ë³€í™˜**: ì‚¬ìš©ìì˜ ìˆ¨ì€ ì˜ë„ë¥¼ íŒŒì•…í•˜ì—¬ ë” êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
-   **ëª¨ë“ˆí˜• êµ¬ì¡°**: Python API ë° CLIë¥¼ ì œê³µí•˜ì—¬ ê¸°ì¡´ ì‹œìŠ¤í…œì— ì†ì‰½ê²Œ í†µí•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸš€ í™œìš© ì‚¬ë¡€

-   ê²€ìƒ‰ì—”ì§„ ê³ ë„í™” ë° ìµœì í™”
-   ì±—ë´‡ ë° ëŒ€í™”í˜• AI ì‹œìŠ¤í…œì˜ ì´í•´ ëŠ¥ë ¥ ê°•í™”
-   ì „ììƒê±°ë˜ ìƒí’ˆ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ
-   RAG(Retrieval-Augmented Generation) ê¸°ë°˜ ì‘ë‹µ ìƒì„± ì‹œìŠ¤í…œì˜ ê²€ìƒ‰ í’ˆì§ˆ ê°œì„ 

---

### ğŸ“‚ ì„¤ì¹˜

#### ì‚¬ì „ ìš”êµ¬ì‚¬í•­
-   **Python**: 3.9 ~ 3.11 ê¶Œì¥
-   **OS**: Windows / Linux / macOS ì§€ì›
-   **(ì„ íƒ)** NVIDIA GPU + CUDAê°€ ì„¤ì¹˜ëœ ê²½ìš° ì¶”ë¡  ì†ë„ê°€ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤.

#!/usr/bin/env bash
set -euo pipefail

### ==============================================================
### 0) ìƒˆ ê°€ìƒí™˜ê²½ ë§Œë“¤ê¸° (conda ë˜ëŠ” venv)
### ==============================================================
echo "=== [0] Python ê°€ìƒí™˜ê²½ ìƒì„± ==="
PY_VER=3.10
if command -v conda &>/dev/null; then
  conda create -n t5qr python=${PY_VER} -y
  source "$(conda info --base)/etc/profile.d/conda.sh"
  conda activate t5qr
else
  python3 -m venv .venv
  source .venv/bin/activate
fi

### ==============================================================
### 1) ì €ì¥ì†Œ í´ë¡  & ì´ë™
### ==============================================================
echo "=== [1] ì €ì¥ì†Œ í´ë¡  ==="
REPO_URL="https://github.com/YOUR_USERNAME/YOUR_REPO_NAME.git"
REPO_DIR="YOUR_REPO_NAME"
if [ ! -d "$REPO_DIR" ]; then
  git clone "$REPO_URL"
fi
cd "$REPO_DIR"

### ==============================================================
### 2) PyTorch ì„¤ì¹˜
### ==============================================================
echo "=== [2] PyTorch ì„¤ì¹˜ ==="
pip install --upgrade pip
if command -v nvidia-smi &>/dev/null; then
  echo "CUDA GPU ê°ì§€ë¨ â†’ GPU ë²„ì „ ì„¤ì¹˜"
  pip install torch --index-url https://download.pytorch.org/whl/cu121
else
  echo "GPU ì—†ìŒ â†’ CPU ë²„ì „ ì„¤ì¹˜"
  pip install torch --index-url https://download.pytorch.org/whl/cpu
fi

### ==============================================================
### 3) ë‚˜ë¨¸ì§€ ì˜ì¡´ì„± ì„¤ì¹˜
### ==============================================================
echo "=== [3] í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ==="
cat > requirements.txt <<'REQ'
transformers>=4.40.0
huggingface_hub>=0.22.0
accelerate>=0.28.0
sentencepiece>=0.1.99
REQ
pip install -r requirements.txt

### ==============================================================
### 4) ì„¤ì¹˜ ê²€ì¦
### ==============================================================
echo "=== [4] ì„¤ì¹˜ ê²€ì¦ ==="
python - <<'PY'
import transformers, sentencepiece, huggingface_hub, torch
print("--- Installation Check ---")
print("transformers:", transformers.__version__)
print("sentencepiece:", sentencepiece.__version__)
print("huggingface_hub:", huggingface_hub.__version__)
print("torch:", torch.__version__)
print("CUDA available:", torch.cuda.is_available())
print("------------------------")
PY

### ==============================================================
### 5) ë¹ ë¥¸ ì‹œì‘ (Python API) í…ŒìŠ¤íŠ¸
### ==============================================================
echo "=== [5] Python API í…ŒìŠ¤íŠ¸ ==="
python - <<'PY'
from transformers import pipeline, set_seed
set_seed(42)

MODEL_ID = "prhegde/t5-query-reformulation-RL"  # ê¸°ë³¸: ì˜ì–´ ëª¨ë¸
# í•œêµ­ì–´ ì…ë ¥ ìœ„ì£¼ë¼ë©´ ì•„ë˜ë¡œ êµì²´:
# MODEL_ID = "KETI-AIR/ke-t5-base"
# MODEL_ID = "paust/pko-t5-base"

rewriter = pipeline(
    "text2text-generation",
    model=MODEL_ID,
    tokenizer=MODEL_ID,
    device=0 if __import__('torch').cuda.is_available() else -1
)

def make_prompt(q: str) -> str:
    return f"ì•„ë˜ ì§ˆì˜ë¥¼ í•œêµ­ì–´ë¡œ ë” êµ¬ì²´ì ì´ê³  ê²€ìƒ‰ì—”ì§„ ì¹œí™”ì ìœ¼ë¡œ ì¬ì‘ì„±:\nì§ˆì˜: {q}\nì¬ì‘ì„±:"

queries = [
    "ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ",
    "ë…¸íŠ¸ë¶ ì‹¸ê²Œ ì‚¬ëŠ” ë²• ì•Œë ¤ì¤˜",
    "ì½”ë¡œë‚˜ ì¦ìƒ ë­ìˆì–´?",
    "ê²¨ìš¸ì— ê°€ë³¼ë§Œí•œ êµ­ë‚´ ì—¬í–‰ì§€ ì¶”ì²œ"
]
prompts = [make_prompt(q) for q in queries]

results = rewriter(
    prompts,
    max_new_tokens=96,
    num_beams=5,
    num_return_sequences=3,
    no_repeat_ngram_size=3
)

for i, q in enumerate(queries):
    print(f"ì›ë³¸ ì¿¼ë¦¬: {q}")
    for j, out in enumerate(results[i]):
        print(f"  => í›„ë³´ {j+1}: {out['generated_text'].strip()}")
    print("-" * 20)
PY

### ==============================================================
### 6) CLI ì‚¬ìš© ì˜ˆì‹œ
### ==============================================================
echo "=== [6] CLI ì˜ˆì‹œ ==="
mkdir -p src
cat > src/infer.py <<'PY'
import argparse
from transformers import pipeline, set_seed
import torch

def main():
    p = argparse.ArgumentParser()
    p.add_argument("--queries", nargs="+", required=True)
    p.add_argument("--model-id", type=str, default="prhegde/t5-query-reformulation-RL")
    p.add_argument("--device", type=int, default=0)
    p.add_argument("--max-new-tokens", type=int, default=96)
    p.add_argument("--num-beams", type=int, default=5)
    p.add_argument("--num-return-sequences", type=int, default=3)
    p.add_argument("--no-repeat-ngram-size", type=int, default=3)
    p.add_argument("--seed", type=int, default=42)
    args = p.parse_args()

    set_seed(args.seed)
    rewriter = pipeline(
        "text2text-generation",
        model=args.model_id,
        tokenizer=args.model_id,
        device=args.device
    )

    def make_prompt(q):
        return f"ì•„ë˜ ì§ˆì˜ë¥¼ í•œêµ­ì–´ë¡œ ë” êµ¬ì²´ì ì´ê³  ê²€ìƒ‰ì—”ì§„ ì¹œí™”ì ìœ¼ë¡œ ì¬ì‘ì„±:\nì§ˆì˜: {q}\nì¬ì‘ì„±:"

    prompts = [make_prompt(q) for q in args.queries]
    results = rewriter(
        prompts,
        max_new_tokens=args.max_new_tokens,
        num_beams=args.num_beams,
        num_return_sequences=args.num_return_sequences,
        no_repeat_ngram_size=args.no_repeat_ngram_size
    )
    for i, q in enumerate(args.queries):
        print(f"ì›ë³¸ ì¿¼ë¦¬: {q}")
        for j, out in enumerate(results[i]):
            print(f"  => í›„ë³´ {j+1}: {out['generated_text'].strip()}")

if __name__ == "__main__":
    main()
PY

echo "CLI ì‹¤í–‰ ì˜ˆ:"
echo "python -m src.infer --queries \"ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ\" \"ê²¨ìš¸ êµ­ë‚´ ì—¬í–‰ì§€ ì¶”ì²œ\" --device 0"

### ==============================================================
### 7) ì˜¤í”„ë¼ì¸/ì‚¬ë‚´ë§ ì˜µì…˜ ì•ˆë‚´
### ==============================================================
echo "=== [7] ì˜¤í”„ë¼ì¸/ì‚¬ë‚´ë§ ì˜µì…˜ ==="
echo "# ì¸í„°ë„· í™˜ê²½ì—ì„œ:"
echo "huggingface-cli login"
echo "huggingface-cli download prhegde/t5-query-reformulation-RL --local-dir ./models/t5qr"
echo "# ì½”ë“œì—ì„œ:"
echo "rewriter = pipeline('text2text-generation', model='./models/t5qr', tokenizer='./models/t5qr', device=0)"

### ==============================================================
### 8) íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì•ˆë‚´
### ==============================================================
cat <<'TIPS'
[ìì£¼ ê²ªëŠ” ì´ìŠˆ]
- HfHubHTTPError: huggingface_hub ì—…ê·¸ë ˆì´ë“œ â†’ pip install -U huggingface_hub
- device_map="auto" ì—ëŸ¬: accelerate ì„¤ì¹˜ í•„ìš” â†’ pip install accelerate
- sentencepiece ê´€ë ¨ ì—ëŸ¬: pip install sentencepiece
- max_new_tokens/max_length ì¤‘ë³µ: í•˜ë‚˜ë§Œ ì‚¬ìš© (ê¶Œì¥ max_new_tokens)
- ì¶œë ¥ì´ : ë˜ëŠ” ì˜ë¯¸ ì—†ìŒ: í•œêµ­ì–´ T5 ëª¨ë¸ë¡œ êµì²´ ë˜ëŠ” ë²ˆì—­ íŒŒì´í”„ë¼ì¸
- GPU ì¸ì‹ ì‹¤íŒ¨: CUDA/PyTorch ë²„ì „ ë¶ˆì¼ì¹˜ í™•ì¸
TIPS

echo "âœ… ëª¨ë“  ì„¤ì¹˜ ë° í…ŒìŠ¤íŠ¸ ì™„ë£Œ"
